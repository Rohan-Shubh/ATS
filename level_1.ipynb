{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Remove language_tool_python dependency and implement a simpler spell checker\n",
    "def simple_spell_check(text):\n",
    "    \"\"\"\n",
    "    A simplified spell checker that looks for common patterns of errors\n",
    "    Returns a rough estimate of text quality\n",
    "    \"\"\"\n",
    "    # Look for common error patterns\n",
    "    potential_errors = [\n",
    "        r'\\b\\w*([a-z]{2,})\\1\\w*\\b',  # Repeated letter patterns\n",
    "        r'\\b\\w*[^a-zA-Z\\s\\'\\-]\\w*\\b',  # Invalid characters\n",
    "        r'\\s{2,}',  # Multiple spaces\n",
    "        r'[A-Z]{2,}[a-z]+'  # Improper capitalization\n",
    "    ]\n",
    "    \n",
    "    error_count = 0\n",
    "    for pattern in potential_errors:\n",
    "        errors = re.findall(pattern, text)\n",
    "        error_count += len(errors)\n",
    "    \n",
    "    total_words = len(text.split())\n",
    "    if total_words == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Return a ratio between 0 and 1, where 1 is best\n",
    "    return max(0, min(1, 1 - (error_count / total_words)))\n",
    "\n",
    "def load_and_clean_data(directory):\n",
    "    \"\"\"Load data from text files in the specified directory and perform initial cleaning.\"\"\"\n",
    "    data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.startswith(\"Resume_of_ID_\") and filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "            id_number = int(filename.split('_')[3].split('.')[0])\n",
    "            clean_text = ' '.join(text.split())  # Remove extra whitespace\n",
    "            data.append({'ID': id_number, 'Text': clean_text})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess text using spaCy for tokenization and lemmatization.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return tokens\n",
    "\n",
    "def extract_years_of_experience(text):\n",
    "    \"\"\"Extract years of experience from the resume text.\"\"\"\n",
    "    years = re.findall(r'\\b(19[7-9]\\d|20[0-2]\\d)\\b', text)\n",
    "    if len(years) >= 2:\n",
    "        earliest_year = min(int(year) for year in years)\n",
    "        latest_year = max(int(year) for year in years)\n",
    "        current_year = datetime.now().year\n",
    "        if latest_year > current_year:\n",
    "            latest_year = current_year\n",
    "        return latest_year - earliest_year\n",
    "    return 0\n",
    "\n",
    "def detect_education_level(text):\n",
    "    \"\"\"Detect the highest education level mentioned in the resume.\"\"\"\n",
    "    education_patterns = {\n",
    "        'PhD': r'\\bPh\\.?D\\.?\\b|\\bDoctor(ate)?\\b',\n",
    "        'Master': r'\\bM\\.?S\\.?\\b|\\bM\\.?A\\.?\\b|\\bMaster\\b',\n",
    "        'Bachelor': r'\\bB\\.?S\\.?\\b|\\bB\\.?A\\.?\\b|\\bBachelor\\b',\n",
    "        'Associate': r'\\bA\\.?S\\.?\\b|\\bA\\.?A\\.?\\b|\\bAssociate\\b'\n",
    "    }\n",
    "\n",
    "    for level, pattern in education_patterns.items():\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            return level\n",
    "    return 'Other'\n",
    "\n",
    "def identify_resume_sections(text):\n",
    "    \"\"\"Identify and score the presence of important resume sections.\"\"\"\n",
    "    important_sections = ['education', 'experience', 'skills', 'projects', 'achievements']\n",
    "    optional_sections = ['summary', 'objective', 'interests', 'activities']\n",
    "    unnecessary_sections = ['references']\n",
    "\n",
    "    section_score = 0\n",
    "    for section in important_sections:\n",
    "        if re.search(r'\\b' + section + r'\\b', text, re.IGNORECASE):\n",
    "            section_score += 1\n",
    "\n",
    "    for section in optional_sections:\n",
    "        if re.search(r'\\b' + section + r'\\b', text, re.IGNORECASE):\n",
    "            section_score += 0.5\n",
    "\n",
    "    for section in unnecessary_sections:\n",
    "        if re.search(r'\\b' + section + r'\\b', text, re.IGNORECASE):\n",
    "            section_score -= 0.5\n",
    "\n",
    "    return min(section_score / len(important_sections), 1)\n",
    "\n",
    "def quantify_brevity(text):\n",
    "    \"\"\"Quantify the brevity of the resume.\"\"\"\n",
    "    word_count = len(text.split())\n",
    "    if word_count < 200:\n",
    "        return 0.5  # Too short\n",
    "    elif word_count > 1000:\n",
    "        return 0.5  # Too long\n",
    "    else:\n",
    "        return 1 - (abs(600 - word_count) / 400)  # Optimal around 600 words\n",
    "\n",
    "def process_resume(row):\n",
    "    \"\"\"Process a single resume and return a dictionary of features.\"\"\"\n",
    "    text = row['Text']\n",
    "    tokens = preprocess_text(text)\n",
    "\n",
    "    years_of_experience = extract_years_of_experience(text)\n",
    "    education_level = detect_education_level(text)\n",
    "    spell_check_ratio = simple_spell_check(text)  # Using our simplified spell checker\n",
    "    section_score = identify_resume_sections(text)\n",
    "    brevity_score = quantify_brevity(text)\n",
    "\n",
    "    return {\n",
    "        'ID': row['ID'],\n",
    "        'Preprocessed_Tokens': tokens,\n",
    "        'Years_of_Experience': years_of_experience,\n",
    "        'Education_Level': education_level,\n",
    "        'Spell_Check_Ratio': spell_check_ratio,\n",
    "        'Section_Score': section_score,\n",
    "        'Brevity_Score': brevity_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "def calculate_word_sentence_counts(text):\n",
    "    \"\"\"Calculate word count and sentence count.\"\"\"\n",
    "    sentences = re.split(r'[.!?]+', text)\n",
    "    word_count = len(text.split())\n",
    "    sentence_count = len([s for s in sentences if s.strip()])\n",
    "    return word_count, sentence_count\n",
    "\n",
    "def extract_skills(text, skill_list):\n",
    "    \"\"\"Extract skills from text based on a predefined skill list.\"\"\"\n",
    "    found_skills = [skill for skill in skill_list if re.search(r'\\b' + re.escape(skill) + r'\\b', text, re.IGNORECASE)]\n",
    "    return found_skills\n",
    "\n",
    "def calculate_skill_match_score(resume_skills, job_skills):\n",
    "    \"\"\"Calculate the skill match score.\"\"\"\n",
    "    if not job_skills:\n",
    "        return 0\n",
    "    matched_skills = set(resume_skills) & set(job_skills)\n",
    "    return len(matched_skills) / len(job_skills)\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    \"\"\"Analyze the sentiment of achievement statements in the resume.\"\"\"\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "def quantify_achievement_impact(text):\n",
    "    \"\"\"Quantify the impact of achievements.\"\"\"\n",
    "    impact_score = 0\n",
    "    achievements = re.findall(r'\\b(increased|decreased|improved|reduced|saved|generated).*?(\\d+(?:\\.\\d+)?%?)', text, re.IGNORECASE)\n",
    "    for _, value in achievements:\n",
    "        if '%' in value:\n",
    "            impact_score += float(value.strip('%')) / 100\n",
    "        else:\n",
    "            impact_score += float(value) / 1000  # Assume larger numbers for non-percentage values\n",
    "    return min(impact_score, 1)\n",
    "\n",
    "def calculate_technical_score(row):\n",
    "    \"\"\"Calculate the technical CV score.\"\"\"\n",
    "    skill_count = len(row['Extracted_Skills'])\n",
    "    experience_score = min(row['Years_of_Experience'] / 10, 1)  # Cap at 10 years\n",
    "    education_score = {'PhD': 1, 'Master': 0.8, 'Bachelor': 0.6, 'Associate': 0.4, 'Other': 0.2}.get(row['Education_Level'], 0.2)\n",
    "\n",
    "    return (skill_count / 10 * 0.4 + experience_score * 0.3 + education_score * 0.3)\n",
    "\n",
    "def calculate_managerial_score(row):\n",
    "    \"\"\"Calculate the managerial CV score.\"\"\"\n",
    "    soft_skills_score = analyze_sentiment(row['Text'])\n",
    "    achievement_impact = quantify_achievement_impact(row['Text'])\n",
    "    leadership_score = min(row['Years_of_Experience'] / 15, 1)  # Assume leadership potential increases with experience\n",
    "\n",
    "    return (soft_skills_score * 0.3 + achievement_impact * 0.4 + leadership_score * 0.3)\n",
    "\n",
    "def calculate_overall_score(row):\n",
    "    \"\"\"Calculate the overall CV score.\"\"\"\n",
    "    technical_score = row['Technical_Score']\n",
    "    managerial_score = row['Managerial_Score']\n",
    "    resume_quality_score = (row['Spell_Check_Ratio'] + row['Section_Score'] + row['Brevity_Score']) / 3\n",
    "    return (technical_score * 0.4 + managerial_score * 0.3 + resume_quality_score * 0.3)\n",
    "\n",
    "def process_resume_section2(row, job_skills):\n",
    "    \"\"\"Process a single resume for Section 2 analysis.\"\"\"\n",
    "    word_count, sentence_count = calculate_word_sentence_counts(row['Text'])\n",
    "\n",
    "    # Combine general and technical skills\n",
    "    all_skills = job_skills['general_skills'] + job_skills['technical_skills']\n",
    "\n",
    "    # Extract skills based on the generated job description\n",
    "    job_specific_skills = extract_skills(row['Generated_Job_Description'], all_skills)\n",
    "    resume_skills = extract_skills(row['Text'], all_skills)\n",
    "\n",
    "    technical_score = calculate_technical_score(row, job_specific_skills)\n",
    "    managerial_score = calculate_managerial_score(row)\n",
    "    resume_quality_score = (row['Spell_Check_Ratio'] + row['Section_Score'] + row['Brevity_Score']) / 3\n",
    "    overall_score = calculate_overall_score(technical_score, managerial_score, resume_quality_score)\n",
    "\n",
    "    return {\n",
    "        'ID': row['ID'],\n",
    "        'Word_Count': word_count,\n",
    "        'Sentence_Count': sentence_count,\n",
    "        'Resume_Skills': resume_skills,\n",
    "        'Job_Specific_Skills': job_specific_skills,\n",
    "        'Technical_Score': technical_score,\n",
    "        'Managerial_Score': managerial_score,\n",
    "        'Resume_Quality_Score': resume_quality_score,\n",
    "        'Overall_Score': overall_score\n",
    "    }\n",
    "\n",
    "def normalize_scores(df):\n",
    "    \"\"\"Normalize scores to ensure fair comparison across all resumes.\"\"\"\n",
    "    score_columns = ['Technical_Score', 'Managerial_Score', 'Resume_Quality_Score', 'Overall_Score']\n",
    "    for column in score_columns:\n",
    "        df[column] = (df[column] - df[column].min()) / (df[column].max() - df[column].min())\n",
    "    return df\n",
    "\n",
    "def process_resumes_section2(df, job_skills):\n",
    "    \"\"\"Process all resumes for Section 2 analysis.\"\"\"\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        results.append(process_resume_section2(row, job_skills))\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    normalized_df = normalize_scores(results_df)\n",
    "    return normalized_df\n",
    "\n",
    "# This function will be called from the main function in Section 3\n",
    "def run_section2(input_file, job_skills):\n",
    "    \"\"\"Run Section 2 processing on the input file.\"\"\"\n",
    "    df = pd.read_csv(input_file)\n",
    "    processed_df = process_resumes_section2(df, job_skills)\n",
    "    processed_df.to_csv('processed_resumes_section2.csv', index=False)\n",
    "    print(\"Section 2 processing completed. Results saved to 'processed_resumes_section2.csv'\")\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "from typing import List, Dict\n",
    "\n",
    "def load_job_skills(file_path: str) -> List[str]:\n",
    "    \"\"\"Load job skills from a JSON file.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def job_description_matching(resume_text: str, job_description: str) -> float:\n",
    "    \"\"\"Calculate similarity between resume and job description.\"\"\"\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform([resume_text, job_description])\n",
    "    return cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
    "\n",
    "def adjust_scores_with_job_match(df: pd.DataFrame, job_description: str) -> pd.DataFrame:\n",
    "    \"\"\"Adjust scores based on job description matching.\"\"\"\n",
    "    df['Job_Match_Score'] = df['Text'].apply(lambda x: job_description_matching(x, job_description))\n",
    "    df['Adjusted_Overall_Score'] = (df['Overall_Score'] * 0.7 + df['Job_Match_Score'] * 0.3)\n",
    "    return df\n",
    "\n",
    "def rank_resumes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Rank resumes based on adjusted overall score.\"\"\"\n",
    "    return df.sort_values('Adjusted_Overall_Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "def generate_report(df: pd.DataFrame, top_n: int = 10) -> Dict:\n",
    "    \"\"\"Generate a report with top candidates and summary statistics.\"\"\"\n",
    "    top_candidates = df.head(top_n)[['ID', 'Adjusted_Overall_Score', 'Technical_Score', 'Managerial_Score', 'Job_Match_Score']]\n",
    "    summary_stats = df[['Adjusted_Overall_Score', 'Technical_Score', 'Managerial_Score', 'Job_Match_Score']].describe()\n",
    "\n",
    "    return {\n",
    "        'top_candidates': top_candidates.to_dict(orient='records'),\n",
    "        'summary_stats': summary_stats.to_dict()\n",
    "    }\n",
    "\n",
    "def match_resume_to_job_description(resume_text, job_description):\n",
    "    \"\"\"Match a resume to a specific job description and return adjusted scores.\"\"\"\n",
    "    # Reuse the existing job_description_matching function\n",
    "    match_score = job_description_matching(resume_text, job_description)\n",
    "\n",
    "    # Recalculate scores based on the new job description\n",
    "    job_specific_skills = extract_skills(job_description, general_job_skills)\n",
    "    resume_skills = extract_skills(resume_text, job_specific_skills)\n",
    "\n",
    "    technical_score = calculate_technical_score({'Text': resume_text, 'Years_of_Experience': extract_years_of_experience(resume_text), 'Education_Level': detect_education_level(resume_text)}, job_specific_skills)\n",
    "    managerial_score = calculate_managerial_score({'Text': resume_text})\n",
    "    resume_quality_score = (simple_spell_check(resume_text) + identify_resume_sections(resume_text) + quantify_brevity(resume_text)) / 3\n",
    "    overall_score = calculate_overall_score(technical_score, managerial_score, resume_quality_score)\n",
    "\n",
    "    adjusted_overall_score = overall_score * 0.7 + match_score * 0.3\n",
    "\n",
    "    return {\n",
    "        'Technical_Score': technical_score,\n",
    "        'Managerial_Score': managerial_score,\n",
    "        'Resume_Quality_Score': resume_quality_score,\n",
    "        'Overall_Score': overall_score,\n",
    "        'Job_Match_Score': match_score,\n",
    "        'Adjusted_Overall_Score': adjusted_overall_score\n",
    "    }\n",
    "\n",
    "def create_default_job_skills_file(file_path):\n",
    "    \"\"\"Create a default job_skills.json file if it doesn't exist.\"\"\"\n",
    "    default_skills = {\n",
    "        \"general_skills\": [\n",
    "            \"communication\", \"teamwork\", \"leadership\", \"problem-solving\",\n",
    "            \"time management\", \"analytical skills\", \"creativity\", \"adaptability\"\n",
    "        ],\n",
    "        \"technical_skills\": [\n",
    "            \"programming\", \"data analysis\", \"project management\",\n",
    "            \"software development\", \"database management\", \"web development\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(default_skills, file, indent=2)\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "def load_job_skills(file_path: str) -> List[str]:\n",
    "    \"\"\"Load general job skills from a JSON file or use a default list.\"\"\"\n",
    "    default_skills = [\n",
    "        \"communication\", \"teamwork\", \"leadership\", \"problem-solving\",\n",
    "        \"time management\", \"analytical skills\", \"creativity\", \"adaptability\",\n",
    "        \"organization\", \"attention to detail\", \"customer service\",\n",
    "        \"critical thinking\", \"decision making\", \"interpersonal skills\",\n",
    "        \"multitasking\", \"flexibility\", \"initiative\", \"reliability\",\n",
    "        \"professionalism\", \"continuous learning\"\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'r') as file:\n",
    "                skills_data = json.load(file)\n",
    "            if isinstance(skills_data, list):\n",
    "                return skills_data\n",
    "            elif isinstance(skills_data, dict) and 'skills' in skills_data:\n",
    "                return skills_data['skills']\n",
    "            else:\n",
    "                print(f\"Unexpected format in '{file_path}'. Using default skills list.\")\n",
    "                return default_skills\n",
    "        else:\n",
    "            print(f\"'{file_path}' not found. Using default skills list.\")\n",
    "            return default_skills\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error reading '{file_path}'. Using default skills list.\")\n",
    "        return default_skills\n",
    "\n",
    "def extract_skills(text: str) -> List[str]:\n",
    "    \"\"\"Extract skills from text using NLP techniques.\"\"\"\n",
    "    # This is a placeholder function. In a real implementation, you would use\n",
    "    # more sophisticated NLP techniques to extract skills from the text.\n",
    "    # For now, we'll use a simple keyword matching approach.\n",
    "    extracted_skills = []\n",
    "    for skill in general_skills:\n",
    "        if skill.lower() in text.lower():\n",
    "            extracted_skills.append(skill)\n",
    "    return extracted_skills\n",
    "\n",
    "def process_resume(row):\n",
    "    \"\"\"Process a single resume and return a dictionary of features.\"\"\"\n",
    "    text = row['Text']\n",
    "\n",
    "    years_of_experience = extract_years_of_experience(text)\n",
    "    education_level = detect_education_level(text)\n",
    "    spell_check_ratio = simple_spell_check(text)\n",
    "    section_score = identify_resume_sections(text)\n",
    "    brevity_score = quantify_brevity(text)\n",
    "    extracted_skills = extract_skills(text)\n",
    "\n",
    "    return {\n",
    "        'ID': row['ID'],\n",
    "        'Years_of_Experience': years_of_experience,\n",
    "        'Education_Level': education_level,\n",
    "        'Spell_Check_Ratio': spell_check_ratio,\n",
    "        'Section_Score': section_score,\n",
    "        'Brevity_Score': brevity_score,\n",
    "        'Extracted_Skills': extracted_skills\n",
    "    }\n",
    "\n",
    "def main(resume_directory: str):\n",
    "    print(\"Starting resume analysis process...\")\n",
    "\n",
    "    # Load general skills\n",
    "    global general_skills\n",
    "    general_skills = load_job_skills('job_skills.json')\n",
    "\n",
    "    # Load and preprocess data\n",
    "    print(\"Loading and preprocessing resumes...\")\n",
    "    df = load_and_clean_data(resume_directory)\n",
    "    df['processed'] = df.apply(process_resume, axis=1)  #here is the problem of language_tool\n",
    "    df = pd.concat([df, pd.DataFrame(df['processed'].tolist())], axis=1)\n",
    "    df.drop('processed', axis=1, inplace=True)\n",
    "\n",
    "    # Calculate scores\n",
    "    df['Skill_Count'] = df['Extracted_Skills'].apply(len)\n",
    "    df['Technical_Score'] = df.apply(calculate_technical_score, axis=1)\n",
    "    df['Managerial_Score'] = df.apply(calculate_managerial_score, axis=1)\n",
    "    df['Overall_Score'] = df.apply(calculate_overall_score, axis=1)\n",
    "\n",
    "    # Rank resumes\n",
    "    print(\"Ranking resumes...\")\n",
    "    ranked_df = df.sort_values('Overall_Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Save final results\n",
    "    final_columns = [\n",
    "        'ID', 'Years_of_Experience', 'Education_Level', 'Spell_Check_Ratio',\n",
    "        'Section_Score', 'Brevity_Score', 'Skill_Count',\n",
    "        'Technical_Score', 'Managerial_Score', 'Overall_Score', 'Extracted_Skills']\n",
    "    ranked_df[final_columns].to_csv('final_ranked_resumes.csv', index=False)\n",
    "\n",
    "    print(\"Resume analysis complete. Results saved to 'final_ranked_resumes.csv'\")\n",
    "\n",
    "    return ranked_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    resume_directory = 'extracted_text_files/'\n",
    "    main(resume_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
